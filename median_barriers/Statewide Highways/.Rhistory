#                values_to = "HitsPer1km") %>%
#   mutate(MedianType = ifelse(grepl("_A$", MedianType_Side), MedianType_A, MedianType_B)) %>%
#   group_by(MedianType) %>%
#   summarise(Aggregated_HitsPer1km = sum(HitsPer1km, na.rm = TRUE))
#
# # Perform Kruskal-Wallis test (non-parametric)
# kruskal_test_result <- kruskal.test(Aggregated_HitsPer1km ~ MedianType, data = aggregated_df)
# print(kruskal_test_result)
# Print the results dataframe
print(wilcox_results_df)
library(dplyr)
library(tidyr)
script_dir <- "C:\\Users\\HP\\Documents\\GitHub\\road-ecology-center\\median_barriers\\Statewide Highways"
source(file.path(script_dir, "process2.R"))
# Perform type comparison on each unique pair
# STEP 1: Reshape df to unique rows by transect
# Count segment length by unique median transect
grouped_segments_df <- segments_df %>%
rename("MedianType" = Primary_Me) %>%
group_by(Pair_Name, Pair_Type, MedianType) %>%
count(MedianType) %>%
mutate("Distance1km" = n*100/1000) # Normalize to 1km distance
# Create a pairing column
paired_df <- grouped_segments_df %>%
mutate(Pair_Column = paste(MedianType, collapse = "_")) %>%
pivot_wider(
names_from = Pair_Name,
values_from = c(n, Distance1km),
names_prefix = "pair_"
) %>%
separate(Pair_Column, into = c("Left_MedianType", "Right_MedianType"), sep = "_")
# Create a dataframe with left and right pairs
pivoted_df <- grouped_segments_df %>%
arrange(Pair_Name, Pair_Type, MedianType) %>%
group_by(Pair_Name, Pair_Type) %>%
mutate(position = row_number()) %>%
pivot_wider(
names_from = c(MedianType, position),
values_from = c(n, Distance1km),
names_sep = "_",
names_glue = "{MedianType}_{.value}_{position}"
) %>%
# Rename columns for clarity
rename(
MedianType_Left = `concrete_n_1`,
MedianType_Right = `gravel_n_2`,
Roadkill_Left = `concrete_n_1`,
Roadkill_Right = `gravel_n_2`,
Segment_Length_Left = `concrete_Distance1km_1`,
Segment_Length_Right = `gravel_Distance1km_2`
)
# Prepare segment data for merge
merge_segment_df <- segment_count %>%
filter(!Primary_Me == "transition") %>% # Remove "transition" records
group_by(Pair_Name, Pair_Type) %>%
summarise(
MedianType_A = first(Primary_Me),
MedianType_B = last(Primary_Me),
Distance1km_A = sum(Distance100m[Primary_Me == MedianType_A]*100/1000),
Distance1km_B = sum(Distance100m[Primary_Me == MedianType_B]*100/1000),
)
# Prepare CROS data for merge
merge_cros_df <- grouped_cros_df %>%
filter(MedianType != "transition") %>% # Remove "transition" records
group_by(Pair_Name, Pair_Type) %>%
summarise(
MedianType_A = strsplit(Pair_Type, "/")[[1]][1],
MedianType_B = strsplit(Pair_Type, "/")[[1]][2],
Hits_A = sum(n[MedianType == strsplit(Pair_Type, "/")[[1]][1]], na.rm = TRUE),
Hits_B = sum(n[MedianType == strsplit(Pair_Type, "/")[[1]][2]], na.rm = TRUE),
.groups = 'drop'  # Ungroup after summarizing
) %>%
mutate(
Hits_B = if_else(is.na(Hits_B), 0, Hits_B)  # Ensure Hits_B is 0 when no full pair
)
# Merge segment and CROS data
merged_df <- merge(merge_cros_df, merge_segment_df,
by=c("Pair_Name", "Pair_Type")) # Should be ~77 pairs
# Clean up dataframe
merged_df <- merged_df %>%
select(!c("MedianType_A.y", "MedianType_B.y")) %>% # Remove duplicate columns
rename( # Rename columns
MedianType_A = MedianType_A.x,
MedianType_B = MedianType_B.x
)
# Filter unwanted pairs
merged_df <- merged_df %>%
filter(!Pair_Name %in% c(
"Willows", #veg/veg, remove for now
"Orland", #veg/veg, remove for now
"I80; Forebay", #median too wide
"I80; Lake Spalding" #median too wide
)) %>%
mutate(
HitsPer1km_A = Hits_A / Distance1km_A,
HitsPer1km_B = Hits_B / Distance1km_B,
HitRateDiff = HitsPer1km_A - HitsPer1km_B
)
# Create wilcoxon test df by pair type
wilcox_df <- merged_df %>% # maybe do barrier/non barrier for all
filter(Pair_Type == "thrie/vegetative")
# STEP 2: Compare WVC counts within each pair
# Perform paired t-test (parametric) or Wilcoxon signed-rank test (non-parametric)
# t_test_result <- t.test(merged_df$HitsPer1km_A, merged_df$HitsPer1km_B, paired = TRUE)
# print(t_test_result)
wilcox_test <- wilcox.test(wilcox_df$HitsPer1km_A, wilcox_df$HitsPer1km_B, paired = TRUE, conf.int = TRUE)
print(wilcox_test)
unique(merged_df$Pair_Type)
# Initialize an empty dataframe to store the results
wilcox_results_df <- data.frame(
Pair_Type = character(),
Test_Statistic = numeric(),
P_Value = numeric(),
Conf_Int_Lower = numeric(),
Conf_Int_Upper = numeric(),
stringsAsFactors = FALSE
)
# Get unique pair types from the dataframe
pair_types <- unique(merged_df$Pair_Type)
# Loop through each pair type and perform the Wilcoxon signed-rank test
for (pair in pair_types) {
# Filter the dataframe for the current pair type
wilcox_df <- merged_df %>% filter(Pair_Type == pair)
# Perform the Wilcoxon signed-rank test
wilcox_test <- wilcox.test(wilcox_df$HitsPer1km_A, wilcox_df$HitsPer1km_B, paired = TRUE, conf.int = TRUE)
# Append the results to the dataframe
wilcox_results_df <- rbind(wilcox_results_df, data.frame(
Pair_Type = pair,
Test_Statistic = wilcox_test$statistic,
P_Value = wilcox_test$p.value,
Conf_Int_Lower = wilcox_test$conf.int[1],
Conf_Int_Upper = wilcox_test$conf.int[2]
))
}
# Print the results dataframe
print(wilcox_results_df)
# Calculate means or medians
mean_hits <- merged_df %>%
group_by(Pair_Type) %>%
summarise(
Mean_HitsPer1km_A = mean(HitsPer1km_A, na.rm = TRUE),
Mean_HitsPer1km_B = mean(HitsPer1km_B, na.rm = TRUE),
Median_HitsPer1km_A = median(HitsPer1km_A, na.rm = TRUE),
Median_HitsPer1km_B = median(HitsPer1km_B, na.rm = TRUE)
)
# Print the results
print(mean_hits)
test <- merged_df %>%
filter(grepl("concrete", Pair_Type)) %>%
filter(!Pair_Type == "concrete/thrie")
wilcox.test(test$HitsPer1km_A, test$HitsPer1km_B, paired = TRUE, conf.int = TRUE)
test <- merged_df %>%
filter(grepl("/vegetative", Pair_Type)) %>%
filter(!grepl("concrete", Pair_Type))
wilcox.test(test$HitsPer1km_A, test$HitsPer1km_B, paired = TRUE, conf.int = TRUE)
test <- merged_df %>%
filter(grepl("/vegetative", Pair_Type))
wilcox.test(test$HitsPer1km_A, test$HitsPer1km_B, paired = TRUE, conf.int = TRUE)
# # STEP 3: Compare aggregate counts across all pairs by median type
#
# # Reshape data for independent testing
# aggregated_df <- merged_df %>%
#   select(MedianType_A, HitsPer1km_A, MedianType_B, HitsPer1km_B) %>%
#   pivot_longer(cols = starts_with("HitsPer1km"),
#                names_to = "MedianType_Side",
#                values_to = "HitsPer1km") %>%
#   mutate(MedianType = ifelse(grepl("_A$", MedianType_Side), MedianType_A, MedianType_B)) %>%
#   group_by(MedianType) %>%
#   summarise(Aggregated_HitsPer1km = sum(HitsPer1km, na.rm = TRUE))
#
# # Perform Kruskal-Wallis test (non-parametric)
# kruskal_test_result <- kruskal.test(Aggregated_HitsPer1km ~ MedianType, data = aggregated_df)
# print(kruskal_test_result)
# Print the results dataframe
print(wilcox_results_df)
library(readxl)
library(dplyr)
# Define the data directory
data_dir <- "D:/Median Barriers/Statewide Highways/Data Outputs"
# List all .xlsx files in the directory and subdirectories
xlsx_files <- list.files(data_dir, pattern = "\\.xlsx$", full.names = TRUE, recursive = TRUE)
# Filter the list to include only files that end with "CROS.xlsx"
cros_files <- xlsx_files[grep("CROS\\.xlsx$", xlsx_files)]
# Function to read each Excel file
read_xlsx_file <- function(file) {
tryCatch({
# Read the file
data <- read_excel(file)
return(data)
}, error = function(e) {
cat("Error reading file:", file, "\nError message:", e$message, "\n")
return(NULL)
})
}
# Read all the CROS.xlsx files and store them in a list
cros_list <- lapply(cros_files, read_xlsx_file)
# Remove any NULL entries (in case some files failed to read)
cros_list <- Filter(Negate(is.null), cros_list)
# Combine all data frames into one
cros_df <- bind_rows(cros_list)
# List of columns to remove
columns_to_remove <- c(
"OBJECTID", "Join_Count",	"TARGET_FID",
"TARGET_FID_1", "Valid_Pair", "Highway_SR", "New_ID", "Field15", "FID_1",
"Join_Count_1", "TARGET_F_1", "Id", "ORIG_FID", "ORIG_SEQ",
"Field15_1", "NEAR_FID", "NEAR_DIST", "NEAR_X", "NEAR_Y", "DDLat", "DDLon", "ORIG_OID",
"Field15_12", "Field15_13", "Valid_Pa_2", "Valid_Pa_3", "Highway__2", "Highway__3",
"TARGET_F_2", "New_ID_12", "New_ID__13", "TARGET_F_3", "OBJECTID_1", "FID_", "Latitude_1",
"Longitud_1", "ORIG_FID_1", "ORIG_SEQ_1", "Pair_Nam_1", "Pair_ID_1",  "Transect_1", "Pair_Typ_1",
"Primary__1", "Median_w_1", "Secondary1", "Notes_1", "Initials_1", "Field14_1",
"NEAR_FID_1", "NEAR_DIS_1", "NEAR_X_1", "NEAR_Y_1", "DDLat_1", "DDLon_1", "ORIG_OID_1",
"Field14", "FID_12", "Join_Cou_1", "Id_1"
)
# Remove unneeded fields
cros_df <- cros_df %>%
select(-one_of(columns_to_remove))
# Rename fields
cros_df <- cros_df %>%
rename(
"Valid" = "Valid_Pa_1",
"Highway" = "Highway__1",
#"Pair_ID" =
"Transect_ID" = "Transect_I",
#"Pair_Type" =
"MedianType" = "Primary_Me",
"MedianWidth" = "Median_wid",
"SecondaryAttribute" = "Secondary_",
"MedianNotes" = "Notes"
#"Initials"
)
# Standardize values
cros_df <- cros_df %>%
mutate(MedianType = case_when( # Standardize values
MedianType == "conc" ~ "concrete",
MedianType == "con" ~ "concrete",
MedianType == "veg" ~ "vegetative",
MedianType == "dirt" ~ "gravel",
TRUE ~ MedianType  # Keep all other values unchanged
)) %>%
mutate(Pair_Type = case_when( # Standardize values
Pair_Type %in% c("conc/veg", "con/veg", "concrete/veg", "veg/conc", "veg/con", "veg/concrete") ~ "concrete/vegetative",
#Pair_Type %in% c("veg/conc", "veg/con") ~ "concrete/vegetative",
Pair_Type == "veg/thrie" ~ "thrie/vegetative",
Pair_Type == "cable/veg" ~ "cable/vegetative",
Pair_Type == "thrie/cable" ~ "thrie/cable",
Pair_Type == "thrie/concrete" ~ "concrete/thrie",
Pair_Type == "veg/veg" ~ "vegetative/vegetative",
#Pair_Type == "veg/concrete" ~ "concrete/vegetative",
Pair_Type == "dirt/double concrete" ~ "concrete/gravel",
Pair_Type == "veg/none" ~ "vegetative/none",
Pair_Type %in% c("concrete/none", "conc/none") ~ "concrete/none",
TRUE ~ Pair_Type  # Keep all other values unchanged
))
# Filter records
cros_df <- cros_df %>%
filter(observatio >= as.POSIXct("2015-01-01 00:00:00")) %>% # Filter by date: (Jan 1, 2015 - April 2024)
filter(chips_An_1 %in% c("Fatality, result of collision", "Fatality, result of dispatch", "Injury") |
condition %in% c("Dead", "Injured"))  # Filter by WVCs
# filter(animal == "Mule (or Black tailed) Deer") # Filter by species
#   #filter(animal == "Black Bear")
#   #group_by(animal) %>%
#count(animal)
# Read in highway segments csv files
# List all .csv files in the directory and subdirectories
csv_files <- list.files(data_dir, pattern = "\\.csv$", full.names = TRUE, recursive = TRUE)
# Filter the list to include only files that do NOT end with "CROS.xlsx"
segments_list <- csv_files[grepl("Segments\\.csv$", csv_files)]
# Function to read each Excel file
read_csv_file <- function(file) {
tryCatch({
# Read the file
data <- read.csv(file)
return(data)
}, error = function(e) {
cat("Error reading file:", file, "\nError message:", e$message, "\n")
return(NULL)
})
}
# Read all the .csv files and store them in a list
segments_list <- lapply(segments_list, read_csv_file)
# Remove any NULL entries (in case some files failed to read)
segments_list <- Filter(Negate(is.null), segments_list)
# Ensure consistent data types for specific columns after reading all data
segments_list <- lapply(segments_list, function(df) {
# Convert "Highway_SR" column to character if it exists
if ("Highway_SR" %in% names(df)) {
df$Highway_SR <- as.character(df$Highway_SR)
}
# Convert "Median_wid" column to character if it exists
if ("Median_wid" %in% names(df)) {
df$Median_wid <- as.character(df$Median_wid)
}
return(df)
})
# Combine all data frames into one df
segments_df <- bind_rows(segments_list)
# Standardize values & clean up columns
segments_df <- segments_df %>%
filter(!is.na(Highway_SR)) %>% # Remove NA median data segments
select(Pair_Name, Valid_Pair, Highway_SR, Pair_ID, Transect_I, Pair_Type, # Remove unnecessary columns
Primary_Me, Median_wid, Secondary_, Latitude, Longitude, Notes, Initials) %>%
mutate(Primary_Me = case_when( # Standardize values
Primary_Me == "conc" ~ "concrete",
Primary_Me == "con" ~ "concrete",
Primary_Me == "veg" ~ "vegetative",
Primary_Me == "dirt" ~ "gravel",
TRUE ~ Primary_Me  # Keep all other values unchanged
)) %>%
mutate(Pair_Type = case_when( # Standardize values
Pair_Type %in% c("conc/veg", "con/veg", "concrete/veg", "veg/conc", "veg/con", "veg/concrete") ~ "concrete/vegetative",
#Pair_Type %in% c("veg/conc", "veg/con") ~ "concrete/vegetative",
Pair_Type == "veg/thrie" ~ "thrie/vegetative",
Pair_Type == "cable/veg" ~ "cable/vegetative",
Pair_Type == "thrie/cable" ~ "thrie/cable",
Pair_Type == "thrie/concrete" ~ "concrete/thrie",
Pair_Type == "veg/veg" ~ "vegetative/vegetative",
#Pair_Type == "veg/concrete" ~ "concrete/vegetative",
Pair_Type == "dirt/double concrete" ~ "concrete/gravel",
Pair_Type == "veg/none" ~ "vegetative/none",
Pair_Type %in% c("concrete/none", "conc/none") ~ "concrete/none",
TRUE ~ Pair_Type  # Keep all other values unchanged
))
# Edit values based on notes to ensure accuracy
segments_df <- segments_df %>%
mutate(Primary_Me = case_when(
Pair_ID == "4" ~ "gravel", # Veg w/ dirt falls under "gravel" type
TRUE ~ Primary_Me
)) %>%
filter(!Pair_ID %in% c("106")) # Median type not consistent across entire transect
# Count segment distance by unique record
segment_count <- segments_df %>%
group_by(Pair_Name, Pair_Type, Primary_Me) %>%
count(Pair_Type) %>%
rename("Distance100m" = n)
# Aggregate roadkill data in df grouped by unique transect record
grouped_cros_df <- cros_df %>%
group_by(Pair_Name, Pair_Type, MedianType) %>%
count(MedianType) %>%
filter(!MedianType %in% c("transition"))
#        !n <= 5)
library(dplyr)
library(tidyr)
script_dir <- "C:\\Users\\HP\\Documents\\GitHub\\road-ecology-center\\median_barriers\\Statewide Highways"
source(file.path(script_dir, "process2.R"))
# Perform type comparison on each unique pair
# STEP 1: Reshape df to unique rows by transect
# Count segment length by unique median transect
grouped_segments_df <- segments_df %>%
rename("MedianType" = Primary_Me) %>%
group_by(Pair_Name, Pair_Type, MedianType) %>%
count(MedianType) %>%
mutate("Distance1km" = n*100/1000) # Normalize to 1km distance
# Create a pairing column
paired_df <- grouped_segments_df %>%
mutate(Pair_Column = paste(MedianType, collapse = "_")) %>%
pivot_wider(
names_from = Pair_Name,
values_from = c(n, Distance1km),
names_prefix = "pair_"
) %>%
separate(Pair_Column, into = c("Left_MedianType", "Right_MedianType"), sep = "_")
# Create a dataframe with left and right pairs
pivoted_df <- grouped_segments_df %>%
arrange(Pair_Name, Pair_Type, MedianType) %>%
group_by(Pair_Name, Pair_Type) %>%
mutate(position = row_number()) %>%
pivot_wider(
names_from = c(MedianType, position),
values_from = c(n, Distance1km),
names_sep = "_",
names_glue = "{MedianType}_{.value}_{position}"
) %>%
# Rename columns for clarity
rename(
MedianType_Left = `concrete_n_1`,
MedianType_Right = `gravel_n_2`,
Roadkill_Left = `concrete_n_1`,
Roadkill_Right = `gravel_n_2`,
Segment_Length_Left = `concrete_Distance1km_1`,
Segment_Length_Right = `gravel_Distance1km_2`
)
# Prepare segment data for merge
merge_segment_df <- segment_count %>%
filter(!Primary_Me == "transition") %>% # Remove "transition" records
group_by(Pair_Name, Pair_Type) %>%
summarise(
MedianType_A = first(Primary_Me),
MedianType_B = last(Primary_Me),
Distance1km_A = sum(Distance100m[Primary_Me == MedianType_A]*100/1000),
Distance1km_B = sum(Distance100m[Primary_Me == MedianType_B]*100/1000),
)
# Prepare CROS data for merge
merge_cros_df <- grouped_cros_df %>%
filter(MedianType != "transition") %>% # Remove "transition" records
group_by(Pair_Name, Pair_Type) %>%
summarise(
MedianType_A = strsplit(Pair_Type, "/")[[1]][1],
MedianType_B = strsplit(Pair_Type, "/")[[1]][2],
Hits_A = sum(n[MedianType == strsplit(Pair_Type, "/")[[1]][1]], na.rm = TRUE),
Hits_B = sum(n[MedianType == strsplit(Pair_Type, "/")[[1]][2]], na.rm = TRUE),
.groups = 'drop'  # Ungroup after summarizing
) %>%
mutate(
Hits_B = if_else(is.na(Hits_B), 0, Hits_B)  # Ensure Hits_B is 0 when no full pair
)
# Merge segment and CROS data
merged_df <- merge(merge_cros_df, merge_segment_df,
by=c("Pair_Name", "Pair_Type")) # Should be ~77 pairs
# Clean up dataframe
merged_df <- merged_df %>%
select(!c("MedianType_A.y", "MedianType_B.y")) %>% # Remove duplicate columns
rename( # Rename columns
MedianType_A = MedianType_A.x,
MedianType_B = MedianType_B.x
)
# Filter unwanted pairs
merged_df <- merged_df %>%
filter(!Pair_Name %in% c(
"Willows", #veg/veg, remove for now
"Orland", #veg/veg, remove for now
"I80; Forebay", #median too wide
"I80; Lake Spalding" #median too wide
)) %>%
mutate(
HitsPer1km_A = Hits_A / Distance1km_A,
HitsPer1km_B = Hits_B / Distance1km_B,
HitRateDiff = HitsPer1km_A - HitsPer1km_B
)
# Create wilcoxon test df by pair type
wilcox_df <- merged_df %>% # maybe do barrier/non barrier for all
filter(Pair_Type == "thrie/vegetative")
# STEP 2: Compare WVC counts within each pair
# Perform paired t-test (parametric) or Wilcoxon signed-rank test (non-parametric)
# t_test_result <- t.test(merged_df$HitsPer1km_A, merged_df$HitsPer1km_B, paired = TRUE)
# print(t_test_result)
wilcox_test <- wilcox.test(wilcox_df$HitsPer1km_A, wilcox_df$HitsPer1km_B, paired = TRUE, conf.int = TRUE)
print(wilcox_test)
unique(merged_df$Pair_Type)
# Initialize an empty dataframe to store the results
wilcox_results_df <- data.frame(
Pair_Type = character(),
Test_Statistic = numeric(),
P_Value = numeric(),
Conf_Int_Lower = numeric(),
Conf_Int_Upper = numeric(),
stringsAsFactors = FALSE
)
# Get unique pair types from the dataframe
pair_types <- unique(merged_df$Pair_Type)
# Loop through each pair type and perform the Wilcoxon signed-rank test
for (pair in pair_types) {
# Filter the dataframe for the current pair type
wilcox_df <- merged_df %>% filter(Pair_Type == pair)
# Perform the Wilcoxon signed-rank test
wilcox_test <- wilcox.test(wilcox_df$HitsPer1km_A, wilcox_df$HitsPer1km_B, paired = TRUE, conf.int = TRUE)
# Append the results to the dataframe
wilcox_results_df <- rbind(wilcox_results_df, data.frame(
Pair_Type = pair,
Test_Statistic = wilcox_test$statistic,
P_Value = wilcox_test$p.value,
Conf_Int_Lower = wilcox_test$conf.int[1],
Conf_Int_Upper = wilcox_test$conf.int[2]
))
}
# Print the results dataframe
print(wilcox_results_df)
# Calculate means or medians
mean_hits <- merged_df %>%
group_by(Pair_Type) %>%
summarise(
Mean_HitsPer1km_A = mean(HitsPer1km_A, na.rm = TRUE),
Mean_HitsPer1km_B = mean(HitsPer1km_B, na.rm = TRUE),
Median_HitsPer1km_A = median(HitsPer1km_A, na.rm = TRUE),
Median_HitsPer1km_B = median(HitsPer1km_B, na.rm = TRUE)
)
# Print the results
print(mean_hits)
test <- merged_df %>%
filter(grepl("concrete", Pair_Type)) %>%
filter(!Pair_Type == "concrete/thrie")
wilcox.test(test$HitsPer1km_A, test$HitsPer1km_B, paired = TRUE, conf.int = TRUE)
test <- merged_df %>%
filter(grepl("/vegetative", Pair_Type)) %>%
filter(!grepl("concrete", Pair_Type))
wilcox.test(test$HitsPer1km_A, test$HitsPer1km_B, paired = TRUE, conf.int = TRUE)
test <- merged_df %>%
filter(grepl("/vegetative", Pair_Type))
wilcox.test(test$HitsPer1km_A, test$HitsPer1km_B, paired = TRUE, conf.int = TRUE)
# # STEP 3: Compare aggregate counts across all pairs by median type
#
# # Reshape data for independent testing
# aggregated_df <- merged_df %>%
#   select(MedianType_A, HitsPer1km_A, MedianType_B, HitsPer1km_B) %>%
#   pivot_longer(cols = starts_with("HitsPer1km"),
#                names_to = "MedianType_Side",
#                values_to = "HitsPer1km") %>%
#   mutate(MedianType = ifelse(grepl("_A$", MedianType_Side), MedianType_A, MedianType_B)) %>%
#   group_by(MedianType) %>%
#   summarise(Aggregated_HitsPer1km = sum(HitsPer1km, na.rm = TRUE))
#
# # Perform Kruskal-Wallis test (non-parametric)
# kruskal_test_result <- kruskal.test(Aggregated_HitsPer1km ~ MedianType, data = aggregated_df)
# print(kruskal_test_result)
View(merged_df)
# Merge segment and CROS data
merged_df <- merge(merge_cros_df, merge_segment_df,
by=c("Pair_Name", "Pair_Type")) # Should be ~77 pairs
View(merge_cros_df)
setdiff(merge_cros_df$Pair_Name, merged_df$Pair_Name)
View(merge_segment_df)
View(segments_df)
unique(segments_df$Pair_Type)
